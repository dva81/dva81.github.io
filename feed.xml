<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://dva81.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dva81.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-24T15:28:42+00:00</updated><id>https://dva81.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">From Concept to Copilot: Defining the Right Intake Criteria</title><link href="https://dva81.github.io/blog/2025/Defining-the-Right-Intake-Criteria/" rel="alternate" type="text/html" title="From Concept to Copilot: Defining the Right Intake Criteria"/><published>2025-03-24T00:00:00+00:00</published><updated>2025-03-24T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2025/Defining%20the%20Right%20Intake%20Criteria</id><content type="html" xml:base="https://dva81.github.io/blog/2025/Defining-the-Right-Intake-Criteria/"><![CDATA[<h1 id="from-concept-to-copilot-defining-the-right-intake-criteria">From Concept to Copilot: Defining the Right Intake Criteria</h1> <p>AI copilots are reshaping how we interact with digital systems, but their success is not accidental—it starts with well-defined intake criteria. Without a structured approach to defining the agent’s functional and technical scope, we risk building copilots that lack usability, accuracy, or security.</p> <p>At the heart of a copilot’s effectiveness are its <strong>functional requirements</strong>—what should it do, and how should it handle various user interactions? A clear <strong>purpose statement</strong> ensures that every decision made in development aligns with a tangible user need. Take customer service AI as an example: defining a “happy flow” where a user asks a question and receives a relevant, concise response minimizes frustration and increases adoption.</p> <p>However, not all user journeys are predictable. An AI agent must also handle <strong>“error flows”</strong>, guiding users to solutions when unexpected inputs arise. In financial services, for instance, a copilot assisting with tax queries should gracefully handle edge cases like ambiguous VAT rules, offering clarifications or escalating complex cases to human experts.</p> <p>Beyond interaction design, <strong>data quality and security</strong> determine a copilot’s reliability. A well-trained model needs <strong>structured, compliant knowledge sources</strong>—be it internal databases or external references. Imagine deploying a legal research assistant that references outdated or conflicting case laws; trust in the system would erode instantly.</p> <p>Finally, <strong>testing and iteration</strong> refine the copilot before deployment. In AI-driven automation, test scenarios should reflect real production data, ensuring the system performs under realistic conditions. A rule of thumb? A development dataset should be at least <strong>20% of the projected production volume</strong>, ensuring robustness before full-scale rollout.</p> <p>A copilot agent is only as good as its <strong>foundations</strong>. Defining clear intake criteria, understanding real-world application needs, and ensuring technical and security readiness—these are the pillars of a successful AI assistant.</p> <p>Here you can find a brief checklist with my most important topics. <a href="https://github.com/dva81/dva81.github.io/assets/pdf/Checklist-Intake_criteria_copilot_Agent.pdf">Checklist-Intake criteria for a Copilot Agent</a></p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[AI copilots are reshaping how we interact with digital systems, but their success is not accidental—it starts with well-defined intake criteria. Without a structured approach to defining the agent’s functional and technical scope, we risk building copilots that lack usability, accuracy, or security.]]></summary></entry><entry><title type="html">Testing Copilot Studio: AI Is Only as Smart as Your Data</title><link href="https://dva81.github.io/blog/2025/AI-Is-Only-as-Smart-as-Your-Data/" rel="alternate" type="text/html" title="Testing Copilot Studio: AI Is Only as Smart as Your Data"/><published>2025-03-21T00:00:00+00:00</published><updated>2025-03-21T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2025/AI%20Is%20Only%20as%20Smart%20as%20Your%20Data</id><content type="html" xml:base="https://dva81.github.io/blog/2025/AI-Is-Only-as-Smart-as-Your-Data/"><![CDATA[<h1 id="testing-copilot-studio-ai-is-only-as-smart-as-your-data">Testing Copilot Studio: AI Is Only as Smart as Your Data</h1> <p>The promise of AI-driven copilots is compelling: streamlined information retrieval, automated workflows, and enhanced efficiency. But as my recent test of Microsoft Copilot Studio for a banking use case demonstrated, the effectiveness of AI is only as good as the data it relies on.</p> <h2 id="the-challenge-finding-the-right-answers">The Challenge: Finding the Right Answers</h2> <p>Our goal was to evaluate how well the Copilot could retrieve precise answers from the bank’s database. The results were mixed. The AI struggled to provide exact matches, primarily due to limitations in data quality and structure.</p> <p>Here’s what we discovered:</p> <ul> <li>The database consisted of .docx documents structured around email-style Q&amp;A exchanges.</li> <li>The search function relied on exact matching of specific content rather than semantic variations of questions.</li> <li>There was no way to test alternative phrasing or conversational queries.</li> <li>Overlapping and inconsistent answers in the dataset made it difficult for the AI to return a definitive response.</li> <li>The business requirements did not allow for AI-generated responses. Only pre-existing text could be retrieved.</li> <li>Data integrity was maintained, as business stakeholders controlled ownership, but this also meant we couldn’t manipulate data to test ideal scenarios.</li> </ul> <h2 id="key-takeaways-fixing-the-foundation">Key Takeaways: Fixing the Foundation</h2> <p>To improve future AI deployments, we need to rethink our approach:</p> <ul> <li><strong>More realistic queries:</strong> Business users must provide better-structured questions to test the AI’s interpretation skills.</li> <li><strong>Improved data quality:</strong> Using platforms like SharePoint to enhance metadata tagging can refine search accuracy.</li> <li><strong>Reducing ambiguity:</strong> Clearer, more distinct responses will help the AI deliver precise answers rather than conflicting outputs. Go in interaction with the data owners to modify the data where possible, under their control.</li> </ul> <h2 id="real-world-implications">Real-World Implications</h2> <p>This isn’t just a technical issue—it’s an operational one. In industries like banking, compliance and accuracy are non-negotiable. AI can’t provide trustworthy automation if it’s built on inconsistent, unstructured data. Our test reinforced a fundamental truth: even the most advanced AI can’t compensate for poor data quality. If the input is flawed, the output will be unreliable.</p> <h2 id="looking-forward">Looking Forward</h2> <p>While our test exposed limitations, it also revealed opportunities. With better data structuring, metadata tagging, and an improved approach to question formulation, AI copilots can be a powerful tool in banking and beyond. But first, we must solve the age-old problem of garbage in, garbage out.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[The promise of AI-driven copilots is compelling. streamlined information retrieval, automated workflows, and enhanced efficiency. But as my recent test of Microsoft Copilot Studio for a banking use case demonstrated, the effectiveness of AI is only as good as the data it relies on.]]></summary></entry><entry><title type="html">From Chatbots to Collaboration - Rethinking AI Agents for Better Workflow Management</title><link href="https://dva81.github.io/blog/2025/Rethinking-AI-Agents-for-Better-Workflow-Management/" rel="alternate" type="text/html" title="From Chatbots to Collaboration - Rethinking AI Agents for Better Workflow Management"/><published>2025-03-10T00:00:00+00:00</published><updated>2025-03-10T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2025/Rethinking%20AI%20Agents%20for%20Better%20Workflow%20Management</id><content type="html" xml:base="https://dva81.github.io/blog/2025/Rethinking-AI-Agents-for-Better-Workflow-Management/"><![CDATA[<p><img src="https://github.com/user-attachments/assets/06ef304c-83dd-41e3-abd3-a6654cab4e06" alt="AI agents in a business setting"/></p> <h1 id="agents-are-everywhere">Agents are everywhere</h1> <p>As someone deeply immersed in the world of AI and productivity tools, I’ve spent significant time working with Copilot Studio. Lately, the term “agents” seems to dominate conversations around business process efficiencies. While the buzz is undeniable, I often find myself questioning whether agents and chatbots are truly the most efficient solutions for addressing workflow challenges.</p> <h1 id="a-means-to-an-end">A means to an end</h1> <p>In our team, we recently embarked on creating an agent designed to integrate seamlessly into a Microsoft Teams channel. Its primary function is straightforward: it prompts everyone in the channel to answer a questions it receives from another bot, redirecting their collective input as an answer to a customer. At first glance, this might seem like an efficient approach to managing inquiries, but there’s an underlying question that needs addressing.</p> <blockquote> <p>“Who takes ownership of this query?”</p> </blockquote> <p>The introduction of agents into workflows brings with it the promise of automation and streamlining. However, it can also risk introducing ambiguity, especially when it comes to accountability. In traditional settings, responsibility often falls upon individuals or dedicated roles. With agents, the lines can blur. Is the agent itself accountable? Or do we rely on human oversight to ensure the job gets done?</p> <blockquote> <p>“Like a Parent WhatsApp Group: AI Agents Keep the Conversation Going, but Someone’s Gotta Wrap It Up.”</p> </blockquote> <p>In our case, while the agent serves as the conduit for gathering input, we’ve established clear protocols for assigning responsibility. The agent’s role is to ask, document, and redirect—human ownership, however, remains integral to ensuring quality and resolution. It’s this delicate interplay between human effort and AI augmentation that underscores the need for thoughtful implementation.</p> <h1 id="final-thoughts">Final thoughts</h1> <p>As businesses continue to embrace the potential of agents, it’s imperative to evaluate their impact not only on efficiency but also on clarity and collaboration within teams. After all, tools should enhance, not complicate, our workflows. It’s not just about adopting the latest technology; it’s about ensuring that technology serves the people behind it.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[I’ve spent significant time working with Copilot Studio. Lately, the term “agents” seems to dominate conversations around business process efficiencies. While the buzz is undeniable, I often find myself questioning whether agents and chatbots are truly the most efficient solutions for addressing workflow challenges.]]></summary></entry><entry><title type="html">Understanding Architecture Roles in IT Organizations</title><link href="https://dva81.github.io/blog/2024/Understanding-Architecture-roles/" rel="alternate" type="text/html" title="Understanding Architecture Roles in IT Organizations"/><published>2024-12-15T00:00:00+00:00</published><updated>2024-12-15T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Understanding-Architecture-roles</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Understanding-Architecture-roles/"><![CDATA[<p>💡 Understanding Architecture Roles in IT Organizations 💡 In our IT landscape, the clarity between different architecture roles is crucial. I came across this overview the other day. It gives a simplified but clear view on the real definitions. The Solution Architect (SA) plays a pivotal role in bridging business requirements with technological solutions. They are the minds behind designing systems that align with business goals and ensuring seamless integration within the existing IT framework. Understanding these distinctions helps in driving better collaboration and achieving strategic success.</p> <p><img src="/assets/img/Understanding Architecture.png" alt="Understanding Architecture"/></p>]]></content><author><name></name></author><category term="Agile"/><category term="Leadership"/><summary type="html"><![CDATA[In our IT landscape, the clarity between different architecture roles is crucial]]></summary></entry><entry><title type="html">AI as a means to work faster</title><link href="https://dva81.github.io/blog/2024/AI-as-a-means-to-work-faster/" rel="alternate" type="text/html" title="AI as a means to work faster"/><published>2024-09-20T00:00:00+00:00</published><updated>2024-09-20T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/AI%20as%20a%20means%20to%20work%20faster</id><content type="html" xml:base="https://dva81.github.io/blog/2024/AI-as-a-means-to-work-faster/"><![CDATA[<h1 id="context">Context</h1> <p>I had a meeting and one of the topics was “the bench”. I had some thoughts on the matter and wanted to write a motivation that can help our organization.</p> <p>I also wanted to see how fast I could make a minimal viable paper 😉 with the help of generative AI and gave myself 30 minutes.</p> <h1 id="lets-get-started">Let’s get started</h1> <p>I wrote some key thoughts and gave them to ChatGPT https://openai.com/chatgpt/overview/</p> <h2 id="first-the-initiatives">First the initiatives</h2> <ul> <li>The bench is not a punishment but an opportunity to grow, expand and train!</li> <li>Content creation</li> <li>Write use cases</li> <li>Blog post and white papers Process improvement</li> <li>Improve the estimation process</li> <li>AI in development Certification</li> <li>Get Certified Training Soft skill training – communication Mastery of skill</li> </ul> <h2 id="then-action-plan">Then Action Plan</h2> <ul> <li>Treat every initiative as a project and not individuals responsibility</li> <li>Administration - Dedicated project codes give insights in effort and result</li> <li>Connect initiatives to personal goals</li> <li>follow up is key – people need guidance and leadership .There is no such thing as self-managing teams</li> </ul> <h2 id="the-result">The result</h2> <p>The draft document of this 30 minutes experiment is next.</p> <blockquote> <p>Not so bad at all…. Happy reading.</p> </blockquote> <h1 id="the-bench-as-an-opportunity-for-growth">The Bench as an opportunity for growth</h1> <p>The concept of “the bench” is often seen in a negative light. However, in our organization, the bench is not a punishment but a valuable opportunity for our teams to grow, expand their skillsets, and train for the future. I would like to highlight several initiatives that can help us leverage this time productively, aligning with our long-term strategic goals.</p> <h2 id="content-creation">Content Creation</h2> <p>Bench time provides our team members with a unique opportunity to contribute to knowledge sharing and brand building through content creation, which helps position us as industry leaders.</p> <p>Write Use Cases: Team members can document recent project experiences, challenges, and solutions that can serve as best practices for the organization and as valuable resources for future projects.</p> <p>Blog Posts and White Papers: Encouraging employees to create blog posts or white papers on relevant industry topics will not only enhance their writing and communication skills but also elevate our company’s thought leadership and digital presence.</p> <h1 id="process-improvement">Process Improvement</h1> <p>Leveraging bench time to refine internal processes is another key area for focus. This can drive efficiency and innovation in our core operations.</p> <p>Improve the Estimation Process: Employees can analyze historical data, identify trends, and develop improved project estimation frameworks that ensure more accurate forecasts for timelines, costs, and resources in future projects.</p> <p>AI in Development: Investigating how AI tools can support and enhance our development processes is another area ripe for exploration. Team members can explore automation, machine learning models, or AI-driven testing processes that will improve efficiency.</p> <h2 id="certification">Certification</h2> <p>Professional certifications not only advance an individual’s career but also enhance the company’s capabilities. Allocating time for employees on the bench to pursue certifications in relevant technologies or methodologies will equip our teams with cutting-edge knowledge.</p> <p>Get Certified: Employees can pursue industry-recognized certifications (e.g., AWS, PMP, Agile, etc.) that align with their expertise and the company’s strategic objectives.</p> <h2 id="training--development">Training &amp; Development</h2> <p>The bench provides an ideal moment for focused professional development through both hard and soft skills training.</p> <p>Soft Skill Training – Communication: Communication is critical to the success of every project. Offering communication workshops will improve team members’ ability to collaborate effectively, articulate their ideas clearly, and engage with clients more professionally.</p> <p>Mastery of Skills: Encourage employees to take time for deep dives into their technical specialties or explore new areas, ensuring they return to client projects with mastery in relevant technologies or methodologies.</p> <h1 id="action-plan-maximizing-the-bench-as-a-growth-opportunity">Action Plan: Maximizing the Bench as a Growth Opportunity</h1> <h2 id="objective">Objective</h2> <p>Transform bench time into a structured, high-value growth opportunity by treating initiatives as formal projects, connecting them to personal goals, and ensuring accountability through leadership and oversight.</p> <h2 id="treat-every-initiative-as-a-project-not-an-individual-responsibility">Treat Every Initiative as a Project, Not an Individual Responsibility</h2> <ul> <li> <p>Action Item: Formalize each initiative (content creation, process improvement, certification, training) as a project with clear deliverables, timelines, and objectives.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Assign a project manager or lead to oversee each initiative, ensuring progress is tracked and goals are met.</p> </li> <li> <p>Establish a project charter for each initiative to clearly define scope, objectives, stakeholders, and outcomes.</p> </li> <li> <p>Ensure team members are aware that these initiatives are formalized projects, not just individual tasks or side assignments.</p> </li> </ul> </li> <li> <p>Success Metric: All initiatives are tracked in a project management system, with clear ownership and regular updates.</p> </li> </ul> <h2 id="administration-dedicated-project-codes-to-track-effort-and-results">Administration: Dedicated Project Codes to Track Effort and Results</h2> <ul> <li> <p>Action Item: Assign dedicated project codes to all bench-related initiatives to track the time and effort spent on each.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Work with the administration team to set up unique project codes for each bench initiative.</p> </li> <li> <p>Ensure that all team members log their hours and progress against these codes in the project management or time-tracking system.</p> </li> <li> <p>Use the data from these codes to review effort, productivity, and overall outcomes, allowing for better resource allocation in future bench periods.</p> </li> </ul> </li> <li> <p>Success Metric: 100% tracking of time spent on initiatives through project codes, leading to data-driven insights into the effectiveness of bench activities.</p> </li> </ul> <h2 id="connect-initiatives-to-personal-goals">Connect Initiatives to Personal Goals</h2> <ul> <li> <p>Action Item: Align each initiative with the individual’s personal growth and development goals, ensuring the initiative adds value both to the organization and the employee.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Conduct one-on-one meetings between managers and team members to discuss personal goals and identify which bench initiatives align with their professional development.</p> </li> <li> <p>Assign individuals to initiatives that help them build skills or gain experience relevant to their career path.</p> </li> <li> <p>Create individualized learning or achievement goals that are linked to the initiatives they are assigned to.</p> </li> </ul> </li> <li> <p>Success Metric: Each team member has a development plan that connects at least one bench initiative to their personal career goals.</p> </li> </ul> <h2 id="follow-up-is-key-leadership-and-guidance-are-crucial">Follow-up Is Key: Leadership and Guidance are Crucial</h2> <ul> <li> <p>Action Item: Establish regular follow-ups and check-ins with team members to provide leadership, support, and direction. Ensure that teams are guided and not left to self-manage.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Schedule bi-weekly or weekly status meetings with initiative leads and team members to review progress, address challenges, and offer guidance.</p> </li> <li> <p>Ensure project managers or team leads are providing clear guidance and setting expectations at each stage of the initiative.</p> </li> <li> <p>Hold leadership accountable for providing regular feedback, mentoring, and removing obstacles that hinder progress.</p> </li> </ul> </li> <li> <p>Success Metric: Consistent follow-up and guidance result in project milestones being met on time, with minimal issues or delays due to lack of leadership.</p> </li> </ul> <h2 id="no-self-managing-teams-provide-structured-oversight">No Self-Managing Teams: Provide Structured Oversight</h2> <ul> <li> <p>Action Item: While encouraging ownership, ensure all teams have clear oversight and leadership to maintain direction and accountability.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Assign a senior leader or project sponsor to each initiative to provide higher-level oversight and ensure alignment with organizational goals.</p> </li> <li> <p>Establish a reporting structure where team leads report on progress, risks, and issues to their sponsors on a regular basis.</p> </li> <li> <p>Implement review checkpoints where senior leadership can assess the impact of initiatives and make adjustments if needed.</p> </li> </ul> </li> <li> <p>Success Metric: All initiatives report progress to leadership on a structured basis, ensuring no initiative is neglected or lacks direction.</p> </li> </ul> <h1 id="conclusion">Conclusion</h1> <p>By treating the bench as a structured opportunity for growth rather than downtime, we can foster a culture of continuous improvement and innovation within our teams. This approach will ensure that our employees remain sharp, motivated, and ready to deliver high-value solutions when they return to active projects. It will also reinforce our reputation as a learning organization that invests in the development of its people.</p> <p>By formalizing bench initiatives as structured projects, assigning appropriate leadership, and connecting them to personal goals, we can ensure that bench time is productive, aligned with both individual and organizational growth, and contributes to long-term success.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[I had a meeting and one of the topics was “the bench”. I had some thoughts on the matter and wanted to write a motivation that can help our organization. I also wanted to see how fast I could make a minimal viable paper 😉 with the help of generative AI and gave myself 30 minutes.]]></summary></entry><entry><title type="html">An advanced pipeline in Azure DevOps and GITHUB for Power Platform Solutions</title><link href="https://dva81.github.io/blog/2024/advanced-pipeline-AzureDevOps/" rel="alternate" type="text/html" title="An advanced pipeline in Azure DevOps and GITHUB for Power Platform Solutions"/><published>2024-07-19T00:00:00+00:00</published><updated>2024-07-19T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/advanced-pipeline-AzureDevOps</id><content type="html" xml:base="https://dva81.github.io/blog/2024/advanced-pipeline-AzureDevOps/"><![CDATA[<p>When working with many developers or designers in highly secure environment with a lot of compliance rules and regulations, Power Platform can be challenging to maintain. In this <a href="https://www.linkedin.com/pulse/azure-devops-easily-deploy-power-platform-solution-dennis-van-aelst-mzfpe/?trackingId=Zt9plSeCTg2OyehjOFpuog%3D%3D">Azure DevOps: Easily deploy a Power platform solution - LinkedIn</a> article, I gave an example on how to create a simple DevOps pipeline.</p> <p>This time I will show you two advanced pipelines to export and import a Power Platform solution with a GITHUB connection. The thought behind this is that the highly regulated enterprises have more complex working environments and deployment needs.</p> <ul> <li>Many developers are working on the same solution in different development environments.</li> <li>Code or configuration check must be done before deploying preferably automated</li> <li>Branching and merging policies.</li> <li>Standard configurations must be added automatically after development</li> </ul> <h1 id="setting-the-stage">Setting the stage</h1> <p>We will be using the following components.</p> <ul> <li>Azure DevOps environment for the build and release pipelines</li> <li>GITHUB repository for storing the configuration and merging the different brances</li> <li>Power Platform environment with a solution to export</li> </ul> <p>The example will be importing from only one environment but it can be extended if needed. If you are reading this article, I can safely assume you know your way around Microsoft Power Platform. However source control is not always related to low code so if you are new to GITHUB check out this Beginner’s guide to GitHub repositories: <a href="https://github.blog/2024-06-24-beginners-guide-to-github-repositories-how-to-create-your-first-repo/">How to create your first repo - The GitHub Blog</a></p> <h1 id="build">Build</h1> <p>There are two pipelines. Get the Solution and Pack and drop.</p> <p><img src="https://github.com/user-attachments/assets/5dd9d6ee-4239-458a-a15f-5a0e658ed683" alt="Build"/></p> <h2 id="get-the-solution">Get the Solution</h2> <p>The goal is to export the solution from the Power Platform environment and store the configuration in GITHUB under a new branch. This way all the components are available in source control and can be handled in code as well. This makes batch updates and checks easier, creating a new version ready to be released via the pack and drop pipeline.</p> <p><img src="https://github.com/user-attachments/assets/1ca58311-b0c7-4854-a3b3-99b42f81540f" alt="Get the Solution"/></p> <p>The first three tasks are simple. Before they start, the Checkout – job creates / clones the Github repo on the agents file system. This way we can use that location to clean the repository before unpacking the solution in that location.</p> <p><img src="https://github.com/user-attachments/assets/48762fd5-985f-4876-a374-871ae7cd5893" alt="Checkout"/></p> <p>In the Clean repo step, The GIT rm command is used to remove the old configuration making it ready to accept the new incoming.</p> <p><img src="https://github.com/user-attachments/assets/801024a4-f39b-4178-bbdc-bca224ed6750" alt="Clean"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>write-host "Set location"
Set-Location -Path $(Build.Repository.LocalPath)

write-host "Start GIT Stuff"
git config user.email "$(Build.RequestedForEmail)"
git config user.name $(Build.RequestedForId)

write-host "Switch"
git switch -c $(Build.BuildId)
</code></pre></div></div> <p>After unpacking, we can send the files to GITHUB in a new branch. I am using predefined variables <a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&amp;tabs=yaml#identity_values">Predefined variables - Azure Pipelines Microsoft Learn</a> because I like standard basic things.</p> <p><img src="https://github.com/user-attachments/assets/18453d97-84e8-4584-9471-6ad541149368" alt="unpacking"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>write-host "Set location"
Set-Location -Path $(Build.Repository.LocalPath)

write-host "Start GIT Stuff"
git config user.email "$(Build.RequestedForEmail)"
git config user.name $(Build.RequestedForId)

write-host "Switch"
git switch -c $(Build.BuildId)
# git checkout -b $(Build.BuildId)

write-host "Adding"
git status
git add *

write-host "Commit"
git commit -m "$(Build.SourceVersionMessage)"
git status

write-host "Push code to new repo"
git -c http.extraheader="AUTHORIZATION: bearer $(System.AccessToken)" push origin $(Build.BuildId)
git status
</code></pre></div></div> <h2 id="things-did-not-go-as-planned">Things did not go as planned</h2> <p>Some things took more time than others. These types configuration of things are an intricate maze of tools, tasks and settings.</p> <p><strong>The Git push did not work</strong></p> <p>The Git push did not work and I got a message the “authentication was not done properly”. I missed a setting in the Agent Job. <a href="https://stackoverflow.com/questions/64803872/azure-pipeline-cannot-prompt-because-terminal-prompts-have-been-disabled">git - Azure Pipeline, Cannot prompt because terminal prompts have been disabled - Stack Overflow</a></p> <p><img src="https://github.com/user-attachments/assets/35fb26fc-d67a-4037-aab1-64c95ce31b3f" alt="push"/></p> <p><strong>Error Not a repo</strong></p> <p>This was because I cleaned the repo before filling it again. I solved this with the GIT rm command. Which did not destroy the cloned repo. <a href="https://komodor.com/blog/solving-fatal-not-a-git-repository-error/">Solved: fatal: Not a git repository (or any of the parent directories): .git (komodor.com)</a></p> <p><strong>Unpack vs unzip does not make a difference.</strong></p> <p>What is strange is that the [Content_types].xml is not extracted in both cases and files in the root are placed in the folder ‘other’. I lost some figering this out. However after packing the Solution, it does create the correct structure again…</p> <p><img src="https://github.com/user-attachments/assets/36170d33-3513-4a48-965a-6a25f9335d15" alt="Unpack"/></p> <p><img src="https://github.com/user-attachments/assets/9ff41786-dcf3-49e2-809f-e3929c48a452" alt="Unpack"/></p> <p><img src="https://github.com/user-attachments/assets/0f476b28-d247-44d9-babf-87d688717027" alt="Unpack"/></p> <h1 id="pack-and-drop">Pack and drop</h1> <p>This pipeline gets the configuration items from the GITHUB repo and packs the Solution again to a managed solution. out of the box you cannot pack from unmanaged to managed and visa versa. The result is a deployable artifact that can be released to any environment. I did not show the deployment settings in the example. Check out my other article for that. You will need to incorporate all connections references and other dependancies like custom connectors.</p> <p><img src="https://github.com/user-attachments/assets/e500ec17-0284-4b47-8b32-3191725d0e80" alt="Pack and drop"/></p> <h1 id="release-pipelines">Release pipelines</h1> <p>The release pipeline is easy. We are working with managed solutions. Unmanaged is not advised! Microsoft considers these as still under development, and you can import or export as unmanaged. You can modify unmanaged solutions. Managed solutions are complete solutions ready for distribution that you cannot modify after importing them to the selected environment. These solutions are intended for production environments. More info on: <a href="https://learn.microsoft.com/en-us/power-apps/maker/data-platform/solution-layers">Solution layers - Power Apps | Microsoft Learn</a></p> <p><img src="https://github.com/user-attachments/assets/2b2f9846-aa55-40f3-9ad2-734128707a09" alt="pipelines"/></p> <p>By using the managed solution all your environments stay nice and clean.</p> <p>Here is an example of a multi stage environment. You can even make this dynamic if you incorporate pipelines and scripts for environment provisioning and use the API for Azure DevOps to automatically create pipelines and release configurations.</p> <p><img src="https://github.com/user-attachments/assets/0f0f5ffb-4e73-4699-88bd-7f27542f00d6" alt="release"/></p> <h1 id="a-parting-note">A parting note</h1> <p>This way method provides a way to introduce all capabilities of modern version control on all aspects of a Power Platform solution. Beware though. You are merging configurations, not real code. The syntax may be ok but that does not mean it will work! The Power Platform is not really intended to use this way. So be carefull!</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[This time I will show you two advanced pipeline to export and import a Power Platform solution with a GITHUB connection. The thought behind this is that the highly regulated enterprises have more complex working environments and deployment needs.]]></summary></entry><entry><title type="html">Skills vs Connectors in Microsoft Copilot Studio - Making the Right Choice</title><link href="https://dva81.github.io/blog/2024/Skills-vs-Connectors/" rel="alternate" type="text/html" title="Skills vs Connectors in Microsoft Copilot Studio - Making the Right Choice"/><published>2024-07-07T00:00:00+00:00</published><updated>2024-07-07T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Skills-vs-Connectors</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Skills-vs-Connectors/"><![CDATA[<p>In the evolving landscape of automation and AI integration, Microsoft Copilot Studio offers two primary methods for enhancing functionality: Skills and Connectors. Understanding the differences, strengths, and best use cases for each can help organizations make informed decisions. This post explores the key aspects of Skills and Connectors, and provides guidance on selecting the right approach for your projects.</p> <h1 id="understanding-connectors">Understanding Connectors</h1> <p>Connectors in the Power Platform provide a low-code solution to integrate various services and applications. This approach is particularly useful for users who want to extend API calls without delving into extensive coding. Here are some key points about Connectors:</p> <ul> <li><strong>Preview Availability</strong>: Connectors are currently available in preview within the Power Platform.</li> <li><strong>Low-Code Approach</strong>: Designed for ease of use, enabling users to integrate services with minimal coding.</li> <li><strong>DLP Policy Impact</strong>: Data Loss Prevention policies apply, with standard limitations allowing 500 calls per minute per connector. These limits are adjustable based on the environment.</li> <li><strong>Authentication</strong>: Proper authentication needs to be verified to ensure secure connections.</li> </ul> <h1 id="exploring-skills">Exploring Skills</h1> <p>Skills offer a more flexible, pro-code approach, requiring Azure infrastructure. This method is ideal for users with coding expertise who need to implement complex customizations. Key features of Skills include:</p> <ul> <li><strong>Pro-Code Flexibility</strong>: Greater flexibility due to the ability to write and modify code.</li> <li><strong>Azure Infrastructure</strong>: Requires setup and management of Azure resources.</li> <li><strong>Extended Capabilities</strong>: Skills can extend further than connectors, especially when paired with Copilot extensions.</li> </ul> <h1 id="user-experience-in-copilot">User Experience in Copilot</h1> <p>Regardless of whether you choose Skills or Connectors, the user experience within Copilot remains largely consistent. Both methods aim to streamline the integration process and enhance functionality.</p> <h1 id="making-the-decision">Making the Decision</h1> <p>For Proof of Concept (POC) use cases, the primary strategy is to use custom connectors. This approach allows for quick integration and testing without extensive coding. However, it’s crucial to continuously evaluate the technical and functional requirements of your project. If the need for more advanced customization arises, considering Skills might be necessary.</p> <h1 id="action-plan">Action Plan</h1> <p>To effectively implement Connectors or Skills, consider the following steps:</p> <ol> <li><strong>Performance Overview</strong>: Assess performance needs and peak usage to estimate the number of API calls required.</li> <li><strong>Limit Adjustments</strong>: Adjust limits as necessary and manage these changes from an Application Lifecycle Management (ALM) perspective.</li> <li><strong>Performance Testing</strong>: Conduct thorough performance testing to ensure the chosen method meets your requirements.</li> </ol> <p>By carefully evaluating your project’s needs and understanding the capabilities of both Skills and Connectors, you can make informed decisions that align with your goals and resources.</p> <hr/> <p>For more detailed information on using Microsoft Bot Framework skills and Power Platform connectors, refer to the official <a href="https://learn.microsoft.com/">Microsoft Copilot Studio documentation</a>.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[This article provides a foundational understanding to help you navigate the choice between Skills and Connectors in Microsoft Copilot Studio.]]></summary></entry><entry><title type="html">Streamline Your Time Tracking - How to Use Outlook and Power Automate for Efficient Reporting</title><link href="https://dva81.github.io/blog/2024/Streamline-Your-Time-Tracking/" rel="alternate" type="text/html" title="Streamline Your Time Tracking - How to Use Outlook and Power Automate for Efficient Reporting"/><published>2024-06-30T00:00:00+00:00</published><updated>2024-06-30T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Streamline-Your-Time-Tracking</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Streamline-Your-Time-Tracking/"><![CDATA[<p>If you are an organized consultant or developer, you might recognize the screenshot from the Outlook calendar below. It’s color-coded, organized, and includes different topics, meetings, customers, and projects. When working with various customers and projects, you often need to fill in timesheets for each one in multiple systems and formats. I constantly lose track and am not good at handling multi-faceted administration across different tools and software. To simplify this, I devised a straightforward method to log all my activities in Outlook and generate simple weekly reports.</p> <p>Check out my post on LinkedIn <a href="https://www.linkedin.com/pulse/streamline-your-time-tracking-how-use-outlook-power-dennis-van-aelst-4u4ne/?trackingId=Gf8WIHj%2FQG27H8lGUZN38g%3D%3D">Streamline Your Time Tracking: How to Use Outlook and Power Automate for Efficient Reporting</a>) .</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><summary type="html"><![CDATA[When working with various customers and projects, you often need to fill in timesheets for each one in multiple systems and formats. I devised a straightforward method to log all my activities in Outlook and generate simple weekly reports.]]></summary></entry><entry><title type="html">Azure DevOps - Easily deploy a Power platform solution</title><link href="https://dva81.github.io/blog/2024/deploy-Power-platform-solutions/" rel="alternate" type="text/html" title="Azure DevOps - Easily deploy a Power platform solution"/><published>2024-06-07T00:00:00+00:00</published><updated>2024-06-07T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/deploy-Power-platform-solutions</id><content type="html" xml:base="https://dva81.github.io/blog/2024/deploy-Power-platform-solutions/"><![CDATA[<p>I have been an Azure DevOps enthusiast for years. The ease of use and flexibility of the platform are super. In this article I am sharing my not-so-complex take on deploying a Power Platform Solution across environments. I will explain how to use a repo, build pipeline and release to different environments.</p> <h1 id="repos">Repos</h1> <p>There is no need to download the solution in a repo if you are not going to manipulate the source / zip file. Using the repo for the deployment settings json file is a good practice as these are configurations that are not managed in the solution. This way you can have version control over the deployment settings. The solution versions are managed in Power Platform or you can roll back from the artifact.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/9ed4499a-b617-44de-9df4-0c93aeb1bd00" alt="image"/></p> <h1 id="pipelines----build-artifact">Pipelines - build artifact</h1> <p>I see pipelines as a means to create a deployable artifact of deployable item. So for me it can be limited to the steps to collect and package the components that need to be deployed. You can either schedule this or start this manually if you are ready to deploy.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/674d2575-bf4e-4d2b-8230-dc44428dd29c" alt="pipeline actions"/></p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/8502521d-d641-4a56-b9ea-ff25f860f638" alt="artifact content"/></p> <p>This package contains everything you need to deploy to any environment. So even if you want to roll back the development environment you can do it with this package.</p> <h1 id="pipelines----release">Pipelines - Release</h1> <p>The release stages are set up from the build output / artifact. Everything is in the artifact, there is no need for other sources. In this example we have three environments to deploy. This can be across tenants if needed. We use the service connections for the connections.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/96a44216-f9fd-4ec3-8ab2-7828c6861566" alt="release stages"/></p> <p>As far as actions go. Always install the tool on the agent and import the solution using the deployment settings json file we configured in the repo.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/9ef2c0b1-f4e7-4589-bc81-546229476b69" alt="stage actions"/></p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/0f5fb92b-1154-436f-8821-8336a7ca3347" alt="deployment settings"/></p> <h1 id="thats-it-no-need-to-overcomplicate">That’s it. No need to overcomplicate.</h1> <p>Hope this helps! Feel free to reach out on LinkedIn.</p> <p>Also check out this post if you are interested in Azure DevOps! <a href="https://www.dennisvanaelst.net/blog/2023/Docs-as-Code/">Boosting Efficiency Docs-as-Code Strategies with Power Platform and Azure DevOps</a> or this https://learn.microsoft.com/en-us/shows/devops-lab/how-to-deploy-power-platform-with-azure-devops</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><summary type="html"><![CDATA[In this article I am sharing my take on deploying a Power Platform Solution across environments. How to use a repo, build pipeline(s) and release to different environments.]]></summary></entry><entry><title type="html">Document Processing with AI Builder - A Practical Guide to the document automation toolkit</title><link href="https://dva81.github.io/blog/2024/AI-builder-quick-guide/" rel="alternate" type="text/html" title="Document Processing with AI Builder - A Practical Guide to the document automation toolkit"/><published>2024-06-05T00:00:00+00:00</published><updated>2024-06-05T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/AI-builder%20quick%20guide</id><content type="html" xml:base="https://dva81.github.io/blog/2024/AI-builder-quick-guide/"><![CDATA[<p>In today’s fast-paced digital landscape, document automation is an essential tool for businesses looking to improve efficiency and accuracy. Microsoft’s AI Builder provides a comprehensive solution for automating document processing, integrating seamlessly with other Microsoft services like SharePoint and Teams. This blog post delves into the workings of the Document Automation Toolkit within AI Builder, detailing the steps involved in setting it up and the adjustments necessary to tailor it to specific needs.</p> <h1 id="getting-started-out-of-the-box-functionality">Getting Started: Out-of-the-Box Functionality</h1> <p>You can access the document automation toolkit in Power Automate. Learn about the toolkit on <a href="https://learn.microsoft.com/en-us/ai-builder/doc-automation">Document automation toolkit - AI Builder | Microsoft Learn</a>. The inital installation is standard and next-next-finish. You do need some knowledge of Power Platform if you want to get started with this.<br/> The two installations I did stalled on the last step but everything looked in working order after a refresh of the browser.</p> <h2 id="1-setting-up-the-solution">1. Setting Up the Solution</h2> <p>To begin, create a new solution within the Power Platform environment and import all toolkit components. The Toolkit comes as a managed solution, so this way you can make the necesary adjustments to the flow’s, apps and dataverse tables. This step is straightforward, enabling users to swiftly set up a foundation for their document automation process. <img src="https://github.com/dva81/dva81.github.io/assets/65031840/6f6d19a2-4ba8-48f5-b961-6a53b5bc43bf" alt="image"/></p> <h2 id="2-model-configuration">2. Model Configuration</h2> <p>Next, create a simple model to complete the initial configuration steps within the app. This involves defining the types of documents to be processed and the data fields to be extracted. <img src="https://github.com/dva81/dva81.github.io/assets/65031840/9eb347fd-6b54-44da-833c-067df788d422" alt="image"/></p> <h2 id="3-base-flow-testing">3. Base Flow Testing</h2> <p>Test the base flow by integrating it with an email system. This initial test ensures that the basic document processing pipeline is functioning correctly.</p> <p>Check and test the email importer flow <img src="https://github.com/dva81/dva81.github.io/assets/65031840/70e4aa74-1942-475f-8547-48d6892ab21c" alt="image"/></p> <p>Configure the Power App to use the correct model. <img src="https://github.com/dva81/dva81.github.io/assets/65031840/4d4fd77b-46be-4219-9fa6-5b3ecc7425d4" alt="image"/></p> <p>Ready to go! <img src="https://github.com/dva81/dva81.github.io/assets/65031840/6b63ee00-ae52-4057-967d-47efda211e02" alt="image"/></p> <h2 id="4-integrating-file-imports">4. Integrating File Imports</h2> <p>Adjust the flow to accommodate file imports from SharePoint or Teams. This integration allows for a seamless transition of documents from these storage solutions into the AI Builder processing pipeline. For this I duplicated the email importer flow and adjusted the steps in the flow to retrieve the files from a sharepoint location.</p> <p>It took only a few hours to get the document automation application up and running. After processing a few documents a few opportunities for improvement emerged.</p> <h1 id="customizing-features-for-enhanced-usability">Customizing Features for Enhanced Usability</h1> <h2 id="1-enhancing-the-user-interface">1. Enhancing the User Interface</h2> <p>The out-of-the-box user interface (UI) includes an interactive table, which may not be entirely user-friendly for all scenarios like high volume input or table manipulation. To improve this, custom buttons and actions were created within the app, enhancing the overall user experience (UX) and making the toolkit more intuitive. I added an add, delete and copy row button and a general save button. The copy function is great if lines have similar text in it and were not extracted properly. And the lay-out was tweaked a bit. The pdf viewer was made a bit smaller to allow for more room for the table and fields.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/22280ec1-a86a-48e5-9f5a-f66a4463c785" alt="image"/></p> <h2 id="2-overcoming-table-structure-challenges">2. Overcoming Table Structure Challenges</h2> <p>In cases where a complex table structure needs to be extracted over multiple pages, the default capabilities of AI Builder might fall short. To address this, optical character recognition (OCR) and a series of regular expressions were employed. This combination allowed for the extraction of complex data structures from documents, ensuring no information was lost during processing.</p> <h2 id="3-addressing-field-restrictions">3. Addressing Field Restrictions</h2> <p>The default character length restriction in Dataverse tables is set to for example 100 characters. For our model, longer field lengths were necessary. Adjusting these settings in Dataverse was possible but initially caused errors during testing. By tweaking these settings and running multiple tests, the issues were eventually resolved, allowing for smoother data processing.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/8d4fa078-950d-4176-a25f-3801a5f67ecd" alt="image"/></p> <h2 id="4-managing-bulk-deletion">4. Managing Bulk Deletion</h2> <p>Bulk deletion of documents is not supported out of the box. To manage this, a manual query was created for document deletion within Dataverse tables. This workaround ensured that unnecessary documents could be efficiently removed without manual intervention.</p> <h1 id="conclusion">Conclusion</h1> <p>Microsoft’s AI Builder and Document Automation Toolkit offers robust features for automating document processing tasks. While the out-of-the-box functionalities provide a solid starting point, specific customizations and adjustments can significantly enhance usability and performance. By addressing UI challenges, overcoming complex table extraction issues, modifying field restrictions, and implementing manual deletion queries, businesses can tailor the AI Builder to meet their unique requirements, ensuring a more efficient and streamlined document automation process.</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><summary type="html"><![CDATA[This blog post delves into the workings of the Document Automation Toolkit within AI Builder, detailing the steps involved in setting it up and the adjustments necessary to tailor it to specific needs.]]></summary></entry></feed>